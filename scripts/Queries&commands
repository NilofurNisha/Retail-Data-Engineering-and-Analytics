

Login to mysql
==============

source /home/hduser/retailorders/ordersproduct_ORIG.sql
source /home/hduser/retailorders/custpayments_ORIG.sql
source /home/hduser/retailorders/empoffice.sql

linux
======

echo -n "root" > ~/root.password

hadoop fs -mkdir /user/hduser/retailorders/
hadoop fs -put ~/root.password /user/hduser/retailorders/root.password
hadoop dfs -chown 400 /user/hduser/retailorders/root.password


sqoop
=======
sqoop --options-file /home/hduser/retailorders/empofficeoption --password-file /user/hduser/retailorders/root.password -table employees -m 2 --delete-target-dir --target-dir /user/hduser/employees/ -fields-terminated-by '~' --lines-terminated-by '\n';

sqoop --options-file /home/hduser/retailorders/empofficeoption --password-file /user/hduser/retailorders/root.password -table offices -m 1 --delete-target-dir --target-dir /user/hduser/offices/ --fields-terminated-by '~' --lines-terminated-by '\n';

sqoop --options-file /home/hduser/retailorders/custoption --password-file /user/hduser/retailorders/root.password --boundary-query " select min(customerNumber),
max(customerNumber) from payments " --query 'select c.customerNumber,upper(c.customerName),c.contactFirstName,c.contactLastName,c.phone,c.addressLine1,c.city,c.state,c.postalCode,c.country ,c.salesRepEmployeeNumber,c.creditLimit ,p.checknumber,p.paymentdate,p.amount from customers c inner join payments p on c.customernumber=p.customernumber where $CONDITIONS' --split-by c.customernumber --delete-target-dir --target-dir /user/hduser/custdetails/2016-10/ --null-string 'NA' --direct --num-mappers 2 --fields-terminated-by '~' --lines-terminated-by '\n';

sqoop --options-file /home/hduser/retailorders/ordersoption --password-file /user/hduser/retailorders/root.password --boundary-query "select min(customerNumber),max(customerNumber) from orders" --query 'select o.customernumber,o.ordernumber,o.orderdate,o.shippeddate,o.status,o.comments,od.productcode,od.quantityordered,od.priceeach,od.orderlinenumber,p.productCode,p.productName,p.productLine,p.productScale,p.productVendor,p.productDescription,p.quantityInStock,p.buyPrice,p.MSRP from orders o inner join orderdetails od on o.ordernumber=od.ordernumber inner join products p on od.productCode=p.productCode where $CONDITIONS' --split-by o.customernumber --delete-target-dir --target-dir /user/hduser/orderdetails/2016-10/ --null-string 'NA' --direct --num-mappers 4 --fields-terminated-by '~' --lines-terminated-by '\n';

Hive
======

create database retail_stg;
use retail_stg;
create table custdetails(customerNumber string,customerName string,contactFirstName string,contactLastName
string,phone bigint,addressLine1 string,city string,state string,postalCode bigint,country
string,salesRepEmployeeNumber string,creditLimit float,checknumber string,paymentdate date, checkamt float)
row format delimited fields terminated by '~'
location '/user/hduser/custdetails/2016-10';

create table custdetstg(customernumber STRING, customername STRING, contactfullname string, address
struct<addressLine1:string,city:string,state:string,postalCode:bigint,country:string,phone:bigint>, creditlimit
float,checknum string,checkamt int,paymentdate date) row format delimited fields terminated by '~' collection items terminated by '$' stored as textfile;

insert overwrite table custdetstg select customernumber,contactfirstname, concat(contactfirstname, ' ',contactlastname) , named_struct('addressLine1', addressLine1, 'city', city, 'state', state, 'postalCode', postalCode,'country', country, 'phone',phone), creditlimit,checknumber,checkamt,paymentdate from retail_stg.custdetails;

create external table orddetstg (customerNumber string, ordernumber string,orderdate date, shippeddate
date,status string, comments string, quantityordered int,priceeach decimal(10,2),orderlinenumber int,
productcode string, productName STRING,productLine STRING, productScale STRING,productVendor
STRING,productDescription STRING,quantityInStock int,buyPrice decimal(10,2),MSRP decimal(10,2))
row format delimited fields terminated by '~'
location '/user/hduser/orderdetails/2016-10/';


hdfs:
=====

hadoop fs -rmr /user/hduser/custorders/custdetpartbuckext

hive
====
create database retail_mart; 
use retail_mart;

set hive.enforce.bucketing = true ;
set map.reduce.tasks = 3;
set hive.exec.dynamic.partition.mode=nonstrict;
set hive.exec.dynamic.partition=true;

create external table custdetpartbuckext (customernumber STRING, customername STRING, contactfullname string, address struct<addressLine1:string,city:string,state:string,postalCode:bigint,country:string,phone:bigint>,creditlimit float,checknum string,checkamt int) partitioned by (paymentdate date) clustered by (customernumber) INTO 3 buckets row format delimited fields terminated by '~' collection items terminated by '$' stored as textfile location '/user/hduser/custorders/custdetpartbuckext';


insert into table custdetpartbuckext partition(paymentdate) select customernumber,customername,contactfullname,address,creditlimit,checknum,checkamt,paymentdate from retail_stg.custdetstg;

create external table orddetpartbuckext(customernumber STRING, ordernumber STRING, shippeddate date,status string, comments string,productcode string,quantityordered int,priceeach decimal(10,2),orderlinenumber int,productName STRING,productLine STRING, productScale STRING,productVendor STRING,productDescription STRING,quantityInStock int,buyPrice decimal(10,2),MSRP decimal(10,2)) partitioned by (orderdate date) clustered by (customernumber) INTO 3 buckets row format delimited fields terminated by '~' collection items terminated by '$' stored as textfile location '/user/hduser/custorders/orddetpartbuckext';

insert into table orddetpartbuckext partition(orderdate) select customernumber,ordernumber, shippeddate,status,comments,productcode,quantityordered ,priceeach ,orderlinenumber ,productName,productLine,productScale,productVendor,productDescription,quantityInStock,buyPrice,MSRP,orderdate from retail_stg.orddetstg ;

Final external tables:

create external table custordfinal (customernumber STRING, customername STRING, contactfullname string, addressLine1 string,city string,state string,country string,phone bigint,creditlimit float,checknum string,checkamt int,ordernumber STRING,shippeddate date,status string, comments string,productcode string,quantityordered int,priceeach decimal(10,2),orderlinenumber int,productName STRING,productLine STRING,productScale STRING,productVendor STRING,productDescription STRING,quantityInStock int,buyPrice decimal(10,2),MSRP decimal(10,2),orderdate date) row format delimited fields terminated by '~' stored as orcfile location '/user/hduser/custorders/custordfinal';



insert into table custordfinal select cd.customernumber,cd.customername, cd.contactfullname, cd.address.addressLine1,cd.address.city,cd.address.state,cd.address.country,cd.address.phone,cd.creditlimit,cd.checknum,cd.checkamt,o.ordernumber,o.shippeddate,o.status,o.comments,o.productcode,o.quantityordered ,o.priceeach,o.orderlinenumber ,o.productName ,o.productLine,
productScale,o.productVendor,o.productDescription,o.quantityInStock,o.buyPrice,o.MSRP,o.orderdate from custdetpartbuckext cd inner join orddetpartbuckext o on cd.customernumber=o.customernumber ;

create external table custordpartfinal (
customernumber STRING, customername STRING, contactfullname string, addressLine1 string,city string,state
string,country string,phone bigint,creditlimit float,checknum string,checkamt int,ordernumber STRING,
shippeddate date,status string, comments string,productcode string,quantityordered int,priceeach
decimal(10,2),orderlinenumber int,productName STRING,productLine STRING,productScale
STRING,productVendor STRING,productDescription STRING,quantityInStock int,buyPrice decimal(10,2),MSRP
decimal(10,2),orderdate date) partitioned by (paymentdate date) row format delimited fields terminated by '~'
stored as textfile location '/user/hduser/custorders/custordpartfinal';

create index idx_custordpartfinal_phone on table custordpartfinal(phone) AS
'org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler' WITH DEFERRED REBUILD;

insert into table custordpartfinal partition(paymentdate) select
cd.customernumber,cd.customername, cd.contactfullname,
cd.address.addressLine1,cd.address.city,cd.address.state,cd.address.country,cd.address.phone
,cd.creditlimit,cd.checknum,cd.checkamt,
o.ordernumber, o.shippeddate,o.status,o.comments,o.productcode,o.quantityordered ,o.priceeach
,o.orderlinenumber ,o.productName ,o.productLine,
productScale,o.productVendor,o.productDescription,o.quantityInStock,o.buyPrice,o.MSRP,o.orderdate,cd.paymentdate
from custdetpartbuckext cd inner join orddetpartbuckext o on cd.customernumber=o.customernumber ;


*******viewship and frustration level
=================================
use retail_stg; drop table if
exists order_rate;
create table retail_stg.order_rate (rid int,orddesc varchar(200),comp_cust varchar(10),siverity int) row format
delimited fields terminated by ',';


load data local inpath '/home/hduser/retailorders/orders_rate.csv' overwrite into table order_rate;

drop table if exists orddetstg;
create table retail_stg.orddetstg (customernumber string,comments string,pagenavigation array
<string>,pagenavigationidx array <int>) row format delimited fields terminated by ',' collection
items terminated by '$';

load data local inpath '/home/hduser/retailorders/stgdata' overwrite into table retail_stg.orddetstg;

hdfs
===== 
hadoop fs -mkdir /user/hduser/custmart/

hive
===========
drop table if exists retail_mart.cust_navigation;
create external table retail_mart.cust_navigation (customernumber string,navigation_pg string,navigation_index
int) row format delimited fields terminated by ',' location '/user/hduser/custmart/';



insert overwrite table retail_mart.cust_navigation select customernumber,pgnavigation as pagenavig
,pgnavigationidx as pagenavigindex from retail_stg.orddetstg lateral view
posexplode(pagenavigation) exploded_data1 as x, pgnavigation lateral view
posexplode(pagenavigationidx) exploded_data2 as y, pgnavigationidx where x=y;

select customernumber,navigation_pg ,row_number() over (partition by customernumber order by
navigation_index desc) as visit_number from retail_mart.cust_navigation;

create external table retail_mart.cust_frustration_level (customernumber string,total_siverity
int,frustration_level string) row format delimited fields terminated by ',' location
'/user/hduser/custmartfrustration/';

insert overwrite table retail_mart.cust_frustration_level select customernumber,total_siverity,case when
total_siverity between -10 and -3 then 'highly frustrated' when total_siverity between -2 and -1 then 'low frustrated' when total_siverity = 0 then 'neutral' when total_siverity between 1 and 2 then 'happy' when total_siverity between 3 and 10 then 'overwhelming' else 'unknown' end as customer_frustration_level from (select customernumber,sum(siverity) as total_siverity from ( select o.customernumber,o.comments,r.orddesc,siverity from retail_stg.orddetstg o left outer join order_rate r where
o.comments like concat('%',r.orddesc,'%')) temp1 group by customernumber) temp2;

select o.customernumber,o.comments,r.orddesc,siverity from retail_stg.orddetstg o left outer join order_rate r where o.comments like concat('%',r.orddesc,'%');
result:
362	They want to reevaluate their terms agreement with Finance.	reevaluate	3

mysql
========
create database customer_reports;
CREATE TABLE customer_reports.customer_frustration_level ( customernumber varchar(200), total_siverity
float,frustration_level varchar(100) );

sqoop
==========
sqoop export --connect jdbc:mysql://localhost/customer_reports --username root --password root --table customer_frustration_level --export-dir /user/hduser/custmartfrustration/



















